{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breakout.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIN35i8DW2XV09zKzPaUp7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzmtsvv/RL-with-gym/blob/main/breakoutv0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ntOB2eN3tzQ"
      },
      "source": [
        "! pip install gym\n",
        "! pip install gym[atari]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNhsvDWe5HuA",
        "outputId": "efccb460-2021-4ce7-d667-77e9b9a3dbd2"
      },
      "source": [
        "! wget http://www.atarimania.com/roms/Roms.rar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-21 13:20:39--  http://www.atarimania.com/roms/Roms.rar\n",
            "Resolving www.atarimania.com (www.atarimania.com)... 195.154.81.199\n",
            "Connecting to www.atarimania.com (www.atarimania.com)|195.154.81.199|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11128004 (11M) [application/x-rar-compressed]\n",
            "Saving to: ‘Roms.rar.1’\n",
            "\n",
            "Roms.rar.1          100%[===================>]  10.61M   475KB/s    in 24s     \n",
            "\n",
            "2021-07-21 13:21:03 (458 KB/s) - ‘Roms.rar.1’ saved [11128004/11128004]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLl4U3Rt5Pvp",
        "outputId": "5f103be6-7a66-406e-ed3e-145ada1e886a"
      },
      "source": [
        "! unzip /content/ROMS.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/ROMS.zip\n",
            "replace ROMS/128 in 1 Game Select ROM (128 in 1) (Unknown) ~.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV-vajOj6ic-"
      },
      "source": [
        "!python -m atari_py.import_roms /content/ROMS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFxPmdyM6o7o"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms as T\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "from collections import deque, namedtuple\n",
        "import gym\n",
        "from gym.wrappers import FrameStack, GrayScaleObservation, TransformObservation\n",
        "from gym.spaces import Box\n",
        "from skimage import transform"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt-bgM8T59xv"
      },
      "source": [
        "env = gym.make('Breakout-v0')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmg4R_Ty6O-3",
        "outputId": "54d706e5-8834-44d0-da22-f12145c4857e"
      },
      "source": [
        "env.reset()\n",
        "next_state, reward, done, info = env.step(action=0)\n",
        "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(210, 160, 3),\n",
            " 0.0,\n",
            " False,\n",
            " {'ale.lives': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4dfoe0o7ihA"
      },
      "source": [
        "def preprocess_state(state):\n",
        "  cropped = Image.fromarray(state).crop((0, 34, 160, 160 + 34))\n",
        "  composition = T.Compose([T.Grayscale(),\n",
        "                           T.Resize((96, 96))])\n",
        "  img = composition(cropped)\n",
        "  small_img = np.uint8(img)\n",
        "  return np.expand_dims(small_img, axis=0)\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "  def __init__(self, capacity):\n",
        "    self.capacity = capacity\n",
        "    self.memory = deque(maxlen=capacity)\n",
        "    self.transition = namedtuple('Transition', ('state', 'action',\n",
        "                                                'next_state', 'reward'))\n",
        "    self.position = 0\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.memory)\n",
        "  \n",
        "  def push(self, *args):\n",
        "    self.memory.append(self.transition(*args))\n",
        "  \n",
        "  def sample(self, batch_size):\n",
        "    return random.sample(self.memory, batch_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLF6ftbu7l6Q"
      },
      "source": [
        "class SkipFrame(gym.Wrapper):\n",
        "  def __init__(self, env, skip):\n",
        "    \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "    super().__init__(env)\n",
        "    self._skip = skip\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Repeat action, and sum reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    done = False\n",
        "    for i in range(self._skip):\n",
        "      # Accumulate reward and repeat the same action\n",
        "      obs, reward, done, info = self.env.step(action)\n",
        "      total_reward += reward\n",
        "      if done:\n",
        "        break\n",
        "    return obs, total_reward, done, info\n",
        "\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "  def __init__(self, env, shape):\n",
        "    super().__init__(env)\n",
        "    if isinstance(shape, int):\n",
        "      self.shape = (shape, shape)\n",
        "    else:\n",
        "      self.shape = tuple(shape)\n",
        "\n",
        "    obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "    self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "  def observation(self, observation):\n",
        "    resize_obs = transform.resize(observation, self.shape)\n",
        "    # cast float back to uint8\n",
        "    resize_obs *= 255\n",
        "    resize_obs = resize_obs.astype(np.uint8)\n",
        "    return resize_obs\n",
        "\n",
        "\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env, keep_dim=False)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "env = TransformObservation(env, f=lambda x: x / 255.)\n",
        "env = FrameStack(env, num_stack=4)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NVt3DRE9Nu8"
      },
      "source": [
        "class ArseNet(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    c, h, w = input_dim\n",
        "    if h != 84:\n",
        "      raise ArithmeticError(f\"Expected input height: 84, got: {h}\")\n",
        "    if w != 84:\n",
        "      raise ArithmeticError(f\"Expected input width: 84, got: {w}\")\n",
        "\n",
        "    self.online = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(3136, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, output_dim)\n",
        "    )\n",
        "    self.target = deepcopy(self.online)\n",
        "\n",
        "    for theta in self.target.parameters():\n",
        "      theta.requires_grad = False\n",
        "  \n",
        "  def forward(self, inputs, model):\n",
        "    if model == 'online':\n",
        "      return self.online(inputs)\n",
        "    elif model == 'target':\n",
        "      return self.target(inputs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQk4BwXv-s8L"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, state_dim, action_dim, save_dir, checkpoint=False):\n",
        "    self.state_dim = state_dim\n",
        "    self.action_dim = action_dim\n",
        "    self.memory = deque(maxlen=100000)\n",
        "    self.batch_size = 32\n",
        "\n",
        "    self.exploration_rate = 1\n",
        "    self.exploration_rate_decay = 0.9999995\n",
        "    self.exploration_rate_min = 0.1\n",
        "    self.gamma = 0.9\n",
        "\n",
        "    self.curr_step = 0\n",
        "    self.burnin = 1e5\n",
        "    self.learn_every = 3\n",
        "    self.sync_every = 1e4\n",
        "\n",
        "    self.save_every = 5e5\n",
        "    self.save_dir = save_dir\n",
        "\n",
        "    self.gpu = torch.cuda.is_available()\n",
        "\n",
        "    self.net = ArseNet(self.state_dim, self.action_dim).float()\n",
        "    if self.gpu:\n",
        "      self.net = self.net.to(device='cuda')\n",
        "    if checkpoint:\n",
        "      self.load(checkpoint)\n",
        "    \n",
        "    self.optimizer = torch.optim.Adam(self.net.parameters(), lr=3e-4)\n",
        "    self.loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "  \n",
        "  def act(self, state):\n",
        "    '''\n",
        "    choose epsilon-greedy action given state and update the value of step\n",
        "    '''\n",
        "    # exploration\n",
        "    if np.random.rand() < self.exploration_rate:\n",
        "      action_idx = np.random.randint(self.action_dim)\n",
        "    # exploitation\n",
        "    else:\n",
        "      torch.cuda.empty_cache()\n",
        "      state = torch.FloatTensor(state).cuda() if self.gpu else torch.FloatTensor(state)\n",
        "      state = state.unsqueeze(0)\n",
        "      action_values = self.net(state, model='online')\n",
        "      action_idx = torch.argmax(action_values, axis=1).item()\n",
        "    \n",
        "    # decrease exploration_rate\n",
        "    self.exploration_rate *= self.exploration_rate_decay\n",
        "    if self.exploration_rate < self.exploration_rate_min:\n",
        "      self.exploration_rate = self.exploration_rate_min\n",
        "    \n",
        "    self.curr_step += 1\n",
        "    return action_idx\n",
        "  \n",
        "  def cache(self, state, next_state, action, reward, done):\n",
        "    '''\n",
        "    store the experience to self.memory\n",
        "    '''\n",
        "    state = torch.FloatTensor(state).cuda() if self.gpu else torch.FloatTensor(state)\n",
        "    next_state = torch.FloatTensor(next_state).cuda() if self.gpu else torch.FloatTensor(next_state)\n",
        "    action = torch.LongTensor([action]).cuda() if self.gpu else torch.LongTensor([action])\n",
        "    reward = torch.DoubleTensor([reward]).cuda() if self.gpu else torch.DoubleTensor([reward])\n",
        "    done = torch.BoolTensor([done]).cuda() if self.gpu else torch.BoolTensor([done])\n",
        "\n",
        "    self.memory.append((state, next_state, action, reward, done,))\n",
        "  \n",
        "  def recall(self):\n",
        "    '''\n",
        "    Take a batch of experience from memory\n",
        "    '''\n",
        "    batch = random.sample(self.memory, self.batch_size)\n",
        "    state, next_state, action, reward, done = map(torch.stack, zip(*batch))\n",
        "    return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()\n",
        "  \n",
        "  def td_estimate(self, state, action):\n",
        "    # the predicted optimal Q_online for a given state\n",
        "    current_Q = self.net(state, model=\"online\")[np.arange(0, self.batch_size), action]\n",
        "    return current_Q\n",
        "  \n",
        "  @torch.no_grad()\n",
        "  def td_target(self, reward, next_state, done):\n",
        "    '''\n",
        "    TD Target - aggregation of current reward and the estimated Q\n",
        "    in the next state\n",
        "    '''\n",
        "    next_state_Q = self.net(state, model='online')\n",
        "    best_action = torch.argmax(next_state_Q, axis=1)\n",
        "    next_Q = self.net(next_state, model='target')[np.arange(0, self.batch_size), best_action]\n",
        "    return (reward + (1 - done.float()) * self.gamma * next_Q).float()\n",
        "  \n",
        "  def update_Q_online(self, td_estimate, td_target):\n",
        "    loss = self.loss_fn(td_estimate, td_target)\n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return loss.item()\n",
        "  \n",
        "  def sync_Q_target(self):\n",
        "    self.net.target.load_state_dict(self.net.online.state_dict())\n",
        "  \n",
        "  def save(self):\n",
        "    num = int(self.curr_step // self.save_every)\n",
        "    save_path = (self.save_dir / f\"mario_net_{num}.chkpt\")\n",
        "    torch.save(dict(model=self.net.state_dict(),\n",
        "                    exploration_rate=self.exploration_rate), save_path)\n",
        "    print(f\"ArseNet saved to {save_path} at step {self.curr_step}\")\n",
        "  \n",
        "  def learn(self):\n",
        "    if not self.curr_step % self.sync_every:\n",
        "      self.sync_Q_target()\n",
        "\n",
        "    # if not self.curr_step % self.save_every:\n",
        "    #  self.save()\n",
        "\n",
        "    if self.curr_step < self.burnin:\n",
        "      return None, None\n",
        "\n",
        "    if self.curr_step % self.learn_every:\n",
        "      return None, None\n",
        "\n",
        "    \n",
        "    # sample from memory\n",
        "    state, next_state, action, reward, done = self.recall()\n",
        "\n",
        "    # TD Estimate and TD Target\n",
        "    td_est = self.td_estimate(state, action)\n",
        "    td_trgt = self.td_target(reward, next_state, done)\n",
        "\n",
        "    loss = self.update_Q_online(td_est, td_trgt)\n",
        "\n",
        "    return td_est.mean().item(), loss\n",
        "  \n",
        "  def save(self):\n",
        "    save_path = self.save_dir / f\"arse_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
        "    torch.save(\n",
        "        dict(\n",
        "            model=self.net.state_dict(),\n",
        "            exploration_rate=self.exploration_rate\n",
        "        ),\n",
        "        save_path\n",
        "    )\n",
        "    print(f\"ArseNet saved to {save_path} at step {self.curr_step}\")\n",
        "  \n",
        "  def load(self, load_path):\n",
        "    if not load_path.exists():\n",
        "      raise ValueError(f\"{load_path} does not exist\")\n",
        "\n",
        "    ckp = torch.load(load_path, map_location=('cuda' if self.gpu else 'cpu'))\n",
        "    exploration_rate = ckp.get('exploration_rate')\n",
        "    state_dict = ckp.get('model')\n",
        "\n",
        "    print(f\"Loading model at {load_path} with exploration rate {exploration_rate}\")\n",
        "    self.net.load_state_dict(state_dict)\n",
        "    self.exploration_rate = exploration_rate"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZLjk-xJAXpg",
        "outputId": "9d28313c-49d2-4b95-81f8-d09426c1d23e"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmShOguBBk2P"
      },
      "source": [
        "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
        "save_dir.mkdir(parents=True)\n",
        "\n",
        "agent = Agent(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXg7LmydBvRP"
      },
      "source": [
        "episodes = 1000\n",
        "rewards = []"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "YaVWsS8OBwIs",
        "outputId": "b21cd940-a735-443c-9ea6-6f302c8d227e"
      },
      "source": [
        "for e in range(episodes):\n",
        "  state = env.reset()\n",
        "\n",
        "  while True:\n",
        "    action = agent.act(state)\n",
        "    next_state, reward, done, info = env.step(action)\n",
        "\n",
        "    agent.cache(state, next_state, action, reward, done)\n",
        "\n",
        "    q, loss = agent.learn()\n",
        "    state = next_state\n",
        "\n",
        "    if done or info['ale.lives'] == 0:\n",
        "      break\n",
        "  \n",
        "  rewards.append(reward)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6a9a3d8a2677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8352fec9251d>\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, state, next_state, action, reward, done)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mstore\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexperience\u001b[0m \u001b[0mto\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     '''\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.76 GiB total capacity; 13.38 GiB already allocated; 3.75 MiB free; 13.69 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMH0JIqSDgzJ"
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNYqs57KFZOc"
      },
      "source": [
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCCv2DqnGdNd",
        "outputId": "d0605876-923a-4676-ea19-bfb4e8292ae9"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f72f0db74d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJaHm9UvGhWA"
      },
      "source": [
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRu9c6jOGkqP"
      },
      "source": [
        "env = wrap_env(env)\n",
        "state = env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df3QmK-HXSBG"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efmeGOH4X0Fh",
        "outputId": "064f6576-5dad-401f-fc5c-9f67f053b771"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 21 14:01:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    31W /  70W |  15106MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DlLHnDrYC-S"
      },
      "source": [
        "agent.gpu = False"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "z6xTC9U6Gmyh",
        "outputId": "5a428b85-d844-40ba-ea5d-1096e14105cb"
      },
      "source": [
        "while not done:\n",
        "    env.render()\n",
        "    agent.net.eval()\n",
        "    action = agent.act(state)\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "env.close()\n",
        "print(total_reward)\n",
        "show_video()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYA0Hov8XLMC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}